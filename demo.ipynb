{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(os.getcwd()) / \"Datasets\" / \"ADNI\" / \"ADNI1\"\n",
    "print(dataset_dir)\n",
    "\n",
    "imgs_dir = dataset_dir / \"Images\"\n",
    "masks_dir = dataset_dir / \"SegmentationMasks\"\n",
    "store_dir = dataset_dir / \"InputImages\"\n",
    "input_dir = store_dir\n",
    "\n",
    "print(imgs_dir)\n",
    "print(masks_dir)\n",
    "\n",
    "csv_files = dataset_dir.glob(\"**/*.csv\")\n",
    "for csv_file in csv_files:\n",
    "    csv_data = csv_file\n",
    "    \n",
    "print(csv_data)\n",
    "df = pd.read_csv(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import models.ResNet as RN\n",
    "_ = importlib.reload(RN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    \"CN\": 0,\n",
    "    \"AD\": 1,\n",
    "}\n",
    "\n",
    "num_classes = len(label_dict.keys())\n",
    "save_path = \"model_resnet_best.pth\"\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RN.ResNet18(device, num_classes)\n",
    "\n",
    "count = 8\n",
    "if count == 1:\n",
    "    save_path = \"model_resnet_best.pth\"\n",
    "else:\n",
    "    save_path = \"model_resnet18_8slices.pth\"\n",
    "\n",
    "model.conv1 = torch.nn.Conv2d(count, model.conv1.out_channels, kernel_size=model.conv1.kernel_size, stride=model.conv1.stride, padding=model.conv1.padding, bias=model.conv1.bias)\n",
    "model.fc2 = torch.nn.Linear(in_features=model.fc2.in_features, out_features=2, bias=True)\n",
    "\n",
    "if os.path.exists(save_path):\n",
    "    print(f\"found saved state at: {save_path}\")\n",
    "    checkpoint = torch.load(save_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])  \n",
    "\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapes = {\n",
    "    (256, 256, 166) : 128,\n",
    "}\n",
    "\n",
    "predict_labels = {\n",
    "    0: \"Cognitively Normal\",\n",
    "    1: \"Alzheimer's Disease\",\n",
    "}\n",
    "\n",
    "def read_image(path):\n",
    "    input_img = nib.load(path).get_fdata()\n",
    "    return input_img\n",
    "\n",
    "def min_max_normalize(image, new_min=0, new_max=1):\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    normalized_image = (image - min_val) / (max_val - min_val) * (new_max - new_min) + new_min\n",
    "    return normalized_image\n",
    "\n",
    "def separate_coronal_slices_around(img, slice_number, slices_count):\n",
    "    slices = []\n",
    "    for slice_no in range(slice_number - slices_count, slice_number + slices_count):\n",
    "        slice = np.rot90(img[:, slice_no, :], k=2)\n",
    "        slice = min_max_normalize(slice)\n",
    "        slices.append(slice) # coronal\n",
    "    return slices\n",
    "\n",
    "def separate_coronal_slices_around1(img, slice_number, slices_count):\n",
    "    slices = []\n",
    "    for slice_no in range(slice_number - slices_count, slice_number + slices_count + 1):\n",
    "        slice = np.rot90(img[:, slice_no, :], k=2)\n",
    "        slice = min_max_normalize(slice)\n",
    "        slices.append(slice) # coronal\n",
    "    return slices\n",
    "\n",
    "\n",
    "def predict(file, age, sex):\n",
    "    img = read_image(file.name)\n",
    "    if img.shape not in input_shapes:\n",
    "        return \"Incorrect file dimensions, try another\"\n",
    "    if count == 8:\n",
    "        coronal_slices = separate_coronal_slices_around(img, input_shapes[img.shape], 4)\n",
    "    else:\n",
    "        coronal_slices = separate_coronal_slices_around1(img, input_shapes[img.shape], 0)\n",
    "    coronal_slices = torch.tensor(coronal_slices, dtype=torch.float).to(device)\n",
    "\n",
    "    x = coronal_slices.unsqueeze(0)\n",
    "    y = torch.tensor((sex, age)).unsqueeze(0).to(device)\n",
    "    model.eval()\n",
    "    output = model(x, y)\n",
    "    return predict_labels[torch.argmax(output).item()]\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=[\n",
    "        gr.File(label=\"Upload .nii file\"),\n",
    "        gr.Slider(1, 100, step=1, label='Age'),\n",
    "        gr.Radio(['Male', 'Female'], label='Sex', type='index')\n",
    "    ],\n",
    "    outputs='text',\n",
    "    title=\"Alzheimer's Disease Detection\"\n",
    ")\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
